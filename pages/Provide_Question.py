import streamlit as st # ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ë§Œë“œëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬
import numpy as np
import random # ë¬´ì‘ìœ„ ì„ íƒì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import PyPDF2 # PDF íŒŒì¼ì„ ë‹¤ë£¨ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬
import io # ì…ì¶œë ¥ ì‘ì—…ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import re # í…ìŠ¤íŠ¸ íŒ¨í„´ì„ ì°¾ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬
import os # íŒŒì¼/í´ë” ê´€ë¦¬ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import pathlib
# import getenv
import openai
from dotenv import load_dotenv # í™˜ê²½ë³€ìˆ˜ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬
from langchain_core.messages.chat import ChatMessage # AI ì±„íŒ… ë©”ì‹œì§€ë¥¼ ë‹¤ë£¨ëŠ” ë„êµ¬
from langchain_openai import ChatOpenAI, OpenAIEmbeddings # OpenAIì˜ AI ëª¨ë¸ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ë„êµ¬
from langchain_core.output_parsers import StrOutputParser # AI ì¶œë ¥ì„ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ëŠ” ë„êµ¬
# from langchain_teddynote.prompts import load_prompt # AI ì§€ì‹œì‚¬í•­ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ë„êµ¬
from langchain_text_splitters import RecursiveCharacterTextSplitter  # ê¸´ í…ìŠ¤íŠ¸ë¥¼ ë‚˜ëˆ„ëŠ” ë„êµ¬
from langchain_community.vectorstores import FAISS # í…ìŠ¤íŠ¸ë¥¼ ê²€ìƒ‰í•˜ê¸° ì‰½ê²Œ ì €ì¥í•˜ëŠ” ë„êµ¬
from langchain_core.runnables import RunnablePassthrough # AI ì²˜ë¦¬ ê³¼ì •ì„ ì—°ê²°í•˜ëŠ” ë„êµ¬
# from langchain_teddynote import logging # ì‘ì—… ê¸°ë¡ì„ ë‚¨ê¸°ëŠ” ë„êµ¬
from langchain_community.document_loaders import PyPDFDirectoryLoader # PDF íŒŒì¼ì„ ì½ëŠ” ë„êµ¬
from langchain.prompts import PromptTemplate # AI ì§€ì‹œì‚¬í•­ í…œí”Œë¦¿ì„ ë§Œë“œëŠ” ë„êµ¬
from streamlit_option_menu import option_menu
from PIL import Image
from utils import switch_page

# PDF ë§¤í•‘ (ë¨¼ì € ì •ì˜í•´ì•¼ í•¨)
CATEGORY_PDF_MAPPING = {
    "python": "C:/Users/USER/REG_project/RAG_project/data/python/python.pdf",
    "machine_learning": "C:/Users/USER/REG_project/RAG_project/data/machine_learning/machine_learning.pdf",
    "deep_learning": "C:/Users/USER/REG_project/RAG_project/data/deep_learning/deep_learning.pdf",
    "data_structure": "C:/Users/USER/REG_project/RAG_project/data/data_structure/data_structure.pdf",
    "operating_system": "C:/Users/USER/REG_project/RAG_project/data/operating_system/operating_system.pdf",
    "network": "C:/Users/USER/REG_project/RAG_project/data/network/network.pdf",
    "statistics": "C:/Users/USER/REG_project/RAG_project/data/statistics/statistics.pdf",
    "algorithm": "C:/Users/USER/REG_project/RAG_project/data/algorithm/algorithm.pdf",
}


# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” í•¨ìˆ˜
def initialize_session_state():
    if "api_key" not in st.session_state:
        st.session_state["api_key"] = None  # API í‚¤ ì €ì¥
    if "selected_category" not in st.session_state:
        st.session_state["selected_category"] = list(CATEGORY_PDF_MAPPING.keys())[0]  # ê¸°ë³¸ ì¹´í…Œê³ ë¦¬
    if "chat_history" not in st.session_state:
        st.session_state["chat_history"] = []  # ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”
    if "messages" not in st.session_state:
        st.session_state["messages"] = []  # ì§ˆë¬¸/ë‹µë³€ ì´ˆê¸°í™”

# PDF ë‚´ìš©ì„ ì½ëŠ” í•¨ìˆ˜
def get_pdf_content(pdf_path):
    try:
        with open(pdf_path, "rb") as pdf_file:
            reader = PyPDF2.PdfReader(pdf_file)
            content = []
            for page in reader.pages:
                content.append(page.extract_text())
            return "\n".join(content)
    except Exception as e:
        st.error(f"PDF ë‚´ìš© ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# PDF ì„ë² ë”© í•¨ìˆ˜
@st.cache_resource(show_spinner="ë©´ì ‘ ì§ˆë¬¸ì„ ì¤€ë¹„í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤...")
def embed_pdf_file(pdf_path, openai_api_key):
    try:
        if not os.path.exists(pdf_path):
            st.error(f"PDF íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {pdf_path}")
            return None

        # PDF ë‚´ìš© ì½ê¸°
        with open(pdf_path, "rb") as pdf_file:
            reader = PyPDF2.PdfReader(pdf_file)
            docs = [page.extract_text() for page in reader.pages if page.extract_text()]

        if not docs:
            st.error("PDF íŒŒì¼ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
            return None

        # í…ìŠ¤íŠ¸ ë¶„í• 
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)
        split_documents = text_splitter.split_text("\n".join(docs))

        # í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±
        embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
        vectorstore = FAISS.from_texts(split_documents, embedding=embeddings)
        return vectorstore.as_retriever()
    except Exception as e:
        st.error(f"PDF ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None




# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ë¬´ì‘ìœ„ ì§ˆë¬¸")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” í˜¸ì¶œ
initialize_session_state()

# ì‚¬ì´ë“œë°”: API í‚¤ ì…ë ¥ ë° ì„¹ì…˜ ì„ íƒ
with st.sidebar:
    st.markdown("### AI ë©´ì ‘ê´€")
    
    # API í‚¤ ì…ë ¥
    openai_api_key = st.text_input("OpenAI API KEY", key="chatbot_api_key", type="password")
    if st.button("API í‚¤ ì €ì¥"):
        if openai_api_key.strip():
            st.session_state["api_key"] = openai_api_key
            st.success("API í‚¤ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
        else:
            st.error("ìœ íš¨í•œ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    # ë¶„ì•¼ ì„ íƒ
    selected_category = st.selectbox(
        "ë¶„ì•¼ë¥¼ ì„ íƒí•˜ì„¸ìš”:",
        list(CATEGORY_PDF_MAPPING.keys()),
        index=list(CATEGORY_PDF_MAPPING.keys()).index(st.session_state["selected_category"]),
    )
    st.session_state["selected_category"] = selected_category

    st.write("ğŸ¯ ë©´ì ‘ ì§ˆë¬¸")
    if not st.session_state["messages"]:
        st.info("ğŸ‘‡ ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ ì²« ë©´ì ‘ ì§ˆë¬¸ì„ ìƒì„±í•´ë³´ì„¸ìš”!")
    else:
        st.info("ğŸ’¡ ìƒˆë¡œìš´ ì§ˆë¬¸ì„ ìƒì„±í•˜ë ¤ë©´ ì•„ë˜ ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”")

# ìƒˆë¡œìš´ ì§ˆë¬¸ ìƒì„± ë²„íŠ¼
    if st.button("ìƒˆë¡œìš´ ì§ˆë¬¸ ìƒì„±", key="new_question_btn"):
        # API í‚¤ í™•ì¸
        if "api_key" not in st.session_state or not st.session_state["api_key"].strip():
            st.error("API í‚¤ë¥¼ ë¨¼ì € ì €ì¥í•´ì£¼ì„¸ìš”.")
            st.stop()
        category = st.session_state["selected_category"]
        pdf_path = CATEGORY_PDF_MAPPING[category]
        if not os.path.exists(pdf_path):
            st.error(f"PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {pdf_path}")
            st.info("í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì˜ PDF íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
            st.stop()
        try:
            content = get_pdf_content(pdf_path)
            if content:
                questions = []
                lines = content.split("\n")

                # ìµœê·¼ 5ê°œ ì§ˆë¬¸ ì¤‘ë³µ ë°©ì§€
                previous_questions = [msg["question"] for msg in st.session_state.get("messages", [])][-5:]
                previous_questions_str = "\n".join(previous_questions) if previous_questions else "ì´ì „ ì§ˆë¬¸ ì—†ìŒ"

                for line in lines:
                    line = line.strip()
                    if line.startswith("`") and line.endswith("`") and len(line) > 10:
                        question_text = line.strip("`").strip()
                        questions.append(question_text)

                if questions:
                    used_questions = {msg["question"] for msg in st.session_state.get("messages", [])}
                    available_questions = [q for q in questions if q not in used_questions]

                    if available_questions:
                        question = random.choice(available_questions)
                        st.session_state["messages"].append({"question": question, "answer": ""})
                        st.session_state["current_question"] = question  # í˜„ì¬ ì§ˆë¬¸ ì €ì¥
                    else:
                        st.warning("ëª¨ë“  ì§ˆë¬¸ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
                else:
                    st.warning("PDFì—ì„œ ë°±í‹±(`)ìœ¼ë¡œ ë‘˜ëŸ¬ì‹¸ì¸ ì§ˆë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.error("PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"PDF íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {str(e)}")
            st.info("PDF íŒŒì¼ì´ ì¡´ì¬í•˜ê³  ì½ê¸° ê°€ëŠ¥í•œì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")

# ë©”ì¸ í™”ë©´: ChatGPT ìŠ¤íƒ€ì¼ ëŒ€í™” ì¸í„°í˜ì´ìŠ¤
st.markdown("## AI ë©´ì ‘ê´€ê³¼ ëŒ€í™”í•˜ê¸°")
st.info("ğŸ’¬ ì´ ì„¸ì…˜ì—ì„œëŠ” AI ë©´ì ‘ê´€ê³¼ ì±„íŒ…ì„ í†µí•´ ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ì£¼ê³ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

# ì´ì „ ëŒ€í™” ë‚´ìš© í‘œì‹œ
if "chat_history" in st.session_state and st.session_state["chat_history"]:
    for chat in st.session_state["chat_history"]:
        if chat["role"] == "ai":
            st.markdown(f"**ğŸ¤– AI ë©´ì ‘ê´€:** {chat['content']}")
        elif chat["role"] == "user":
            st.markdown(f"**ğŸ‘¤ ì‚¬ìš©ì:** {chat['content']}")

# ì‚¬ìš©ì ì…ë ¥ë€
st.markdown("### ğŸ‘‡ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì…ë ¥í•˜ì„¸ìš”:")
user_input = st.text_input("")

# ì‘ë‹µ ì²˜ë¦¬
if st.button("ì „ì†¡"):
    if user_input.strip():
        # ì‚¬ìš©ì ì…ë ¥ ê¸°ë¡
        st.session_state["chat_history"].append({"role": "user", "content": user_input})

        # AI ë‹µë³€ ìƒì„± (ì˜ˆì œ, ì‹¤ì œ OpenAI API í˜¸ì¶œ ê°€ëŠ¥)
        ai_response = f"'{user_input}'ì— ëŒ€í•œ ì¢‹ì€ ëŒ€ë‹µì…ë‹ˆë‹¤! ì¶”ê°€ë¡œ ë‹¤ìŒ ì§ˆë¬¸ì„ ìƒê°í•´ë³´ì„¸ìš”."
        st.session_state["chat_history"].append({"role": "ai", "content": ai_response})

        # ì¶œë ¥ ì—…ë°ì´íŠ¸
        st.experimental_rerun()
    else:
        st.warning("ë¹ˆ ì…ë ¥ì€ í—ˆìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

# ì§ˆë¬¸ í‘œì‹œ
if "current_question" in st.session_state and st.session_state["current_question"]:
    st.markdown(f"### ğŸ§ í˜„ì¬ ì§ˆë¬¸: {st.session_state['current_question']}")
else:
    st.info("ì§ˆë¬¸ì„ ìƒì„±í•˜ë ¤ë©´ ì‚¬ì´ë“œë°”ì—ì„œ ì„ íƒí•˜ì„¸ìš”.")

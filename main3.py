import os
import streamlit as st
from dotenv import load_dotenv
from langchain_core.messages.chat import ChatMessage
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.output_parsers import StrOutputParser
from langchain_teddynote.prompts import load_prompt
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_core.runnables import RunnablePassthrough
from langchain_teddynote import logging
from langchain_community.document_loaders import PyPDFDirectoryLoader

# API Key ì •ë³´ë¡œë“œ
load_dotenv()

# í”„ë¡œì íŠ¸ ì´ë¦„ì„ ì…ë ¥í•©ë‹ˆë‹¤.
logging.langsmith("[Project] PDF_RAG")

# ìºì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
if not os.path.exists(".cache"):
    os.mkdir(".cache")
if not os.path.exists(".cache/files"):
    os.mkdir(".cache/files")
if not os.path.exists(".cache/embeddings"):
    os.mkdir(".cache/embeddings")

# Streamlit title
st.title("AI ì›¹ ê°œë°œì ë©´ì ‘ íŠœí„°ë§ğŸš€")

# ëŒ€í™” ì´ˆê¸°í™” ë° ë©”ì‹œì§€ ì €ì¥
if "messages" not in st.session_state:
    st.session_state["messages"] = []
if "chain" not in st.session_state:
    st.session_state["chain"] = None
if "selected_category" not in st.session_state:
    st.session_state["selected_category"] = None

# PDF ë””ë ‰í† ë¦¬ì—ì„œ ë‹¤ìˆ˜ì˜ íŒŒì¼ì„ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜
@st.cache_resource(show_spinner="ë©´ì ‘ì§ˆë¬¸ì„ ì¤€ë¹„í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤...")
def embed_files_from_directory(directory_path):
    try:
        # ë””ë ‰í† ë¦¬ ê²½ë¡œ í™•ì¸
        if not os.path.exists(directory_path):
            st.error(f"ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {directory_path}")
            return None

        # ë””ë ‰í† ë¦¬ì— PDF íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
        pdf_files = [f for f in os.listdir(directory_path) if f.endswith('.pdf')]
        if not pdf_files:
            st.error(f"ë””ë ‰í† ë¦¬ì— PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {directory_path}")
            return None

        # PyPDFDirectoryLoaderë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¤ìˆ˜ì˜ PDF íŒŒì¼ì„ ë¡œë“œ
        loader = PyPDFDirectoryLoader(directory_path)
        docs = loader.load()

        if not docs:
            st.error("PDF íŒŒì¼ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë””ë ‰í† ë¦¬ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            return None

        # ë¬¸ì„œ ë¶„í• (Split Documents)
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)
        split_documents = text_splitter.split_documents(docs)

        if not split_documents:
            st.error("ë¬¸ì„œë¥¼ ë¶„í• í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. PDF íŒŒì¼ì˜ ë‚´ìš©ì„ í™•ì¸í•˜ì„¸ìš”.")
            return None

        # ì„ë² ë”©(Embedding) ìƒì„±
        embeddings = OpenAIEmbeddings()

        # ë²¡í„°ìŠ¤í† ì–´ ìƒì„±(Create DB) ë° ì €ì¥
        vectorstore = FAISS.from_documents(documents=split_documents, embedding=embeddings)

        # ê²€ìƒ‰ê¸°(Retriever) ìƒì„±
        retriever = vectorstore.as_retriever()
        return retriever
    except Exception as e:
        st.error(f"PDF íŒŒì¼ì„ ë¡œë“œí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return None

# ì¹´í…Œê³ ë¦¬ ì„ íƒ
category = st.selectbox("ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•˜ì„¸ìš”:", ["ë¨¸ì‹ ëŸ¬ë‹", "ë„¤íŠ¸ì›Œí¬", "í†µê³„", "íŒŒì´ì¬"])

# ì¹´í…Œê³ ë¦¬ì— ë”°ë¼ ë””ë ‰í† ë¦¬ ì„¤ì •
directory_mapping = {
    "ë¨¸ì‹ ëŸ¬ë‹": "data/machine_learning/",
    "ë„¤íŠ¸ì›Œí¬": "data/network/",
    "í†µê³„": "data/statistics/",
    "íŒŒì´ì¬": "data/python/"
}

# ë””ë ‰í† ë¦¬ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ ë° ìƒì„±
for path in directory_mapping.values():
    if not os.path.exists(path):
        os.makedirs(path)

# ì¹´í…Œê³ ë¦¬ì— ë”°ë¼ ë””ë ‰í† ë¦¬ ì„¤ì • ë° ì²´ì¸ ìƒì„±
if st.session_state["chain"] is None or st.session_state["selected_category"] != category:
    st.session_state["chain"] = embed_files_from_directory(directory_mapping[category])
    st.session_state["selected_category"] = category

# í”„ë¡¬í”„íŠ¸ ë¡œë“œ (ë°±ì—”ë“œì—ì„œë§Œ ì²˜ë¦¬)
question_prompt = load_prompt("prompts/question_prompt.yaml")  # ì§ˆë¬¸ ìƒì„±ìš© í”„ë¡¬í”„íŠ¸
feedback_prompt = load_prompt("prompts/feedback_prompt.yaml")  # í”¼ë“œë°± ìƒì„±ìš© í”„ë¡¬í”„íŠ¸

# ë©´ì ‘ ì§ˆë¬¸ ìƒì„± ë° í‘œì‹œ
if st.session_state["chain"]:
    col1, col2 = st.columns([3, 1])
    with col1:
        # ê¸°ì¡´ ëŒ€í™” ë‚´ìš© í‘œì‹œ
        for i, message in enumerate(st.session_state["messages"]):
            st.write(f"Q: {message['question']}")
            # ë‹µë³€ì´ ìˆìœ¼ë©´ í‘œì‹œ ë° í”¼ë“œë°± ì œê³µ
            if message['answer']:
                st.write(f"A: {message['answer']}")
                
                # ë‹µë³€ì— ëŒ€í•œ í”¼ë“œë°±ì´ ì—†ëŠ” ê²½ìš°ì—ë§Œ ìƒì„±
                if 'feedback' not in message:
                    retriever = st.session_state["chain"]
                    docs = retriever.get_relevant_documents(message['question'])
                    
                    if docs:
                        context = docs[0].page_content
                        feedback_chain = feedback_prompt | ChatOpenAI(temperature=0.3) | StrOutputParser()
                        feedback = feedback_chain.invoke({
                            "context": context,
                            "question": message['question'],
                            "answer": message['answer']
                        })
                        
                        st.session_state["messages"][i]["feedback"] = feedback
                        st.rerun()
                
                # í”¼ë“œë°± í‘œì‹œ
                if 'feedback' in message:
                    st.write("ğŸ’¡ í”¼ë“œë°±:")
                    st.write(message['feedback'])
            else:
                # ì‚¬ìš©ì ë‹µë³€ ì…ë ¥ì°½
                user_answer = st.text_area("ë‹µë³€ì„ ì…ë ¥í•˜ì„¸ìš”:", key=f"answer_{i}")
                if st.button("ë‹µë³€ ì œì¶œ", key=f"submit_{i}"):
                    st.session_state["messages"][i]["answer"] = user_answer
                    st.rerun()
    
    # ìƒˆë¡œìš´ ì§ˆë¬¸ ìƒì„± ë²„íŠ¼
    with col2:
        if st.button("ìƒˆë¡œìš´ ì§ˆë¬¸ ìƒì„±"):
            retriever = st.session_state["chain"]
            docs = retriever.get_relevant_documents(category)
            
            if docs:
                context = docs[0].page_content
                question_chain = question_prompt | ChatOpenAI(temperature=0.7) | StrOutputParser()
                question = question_chain.invoke({"context": context})
                
                st.session_state["messages"].append({"question": question, "answer": ""})
                st.rerun()
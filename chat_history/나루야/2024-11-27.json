[
  {
    "question": "Test 세트가  오염되었다는  말의  뜻은  무엇인가요 ?",
    "answer": "test 데이터는 한 번도 학습에서 본 적 없는 데이터여야 한다. 그런데 train 데이터가test 데이터와 흡사하거나 포함되기까지한다면 test 데이터는 더이상 학습된 모델의성능 평가를 객관적으로 하지 못한다.",
    "feedback": "1. 답변의 좋은 점:\n지원자는 test 데이터가 학습된 모델의 성능을 평가하는 데에 있어서 객관적이지 못하다는 점을 잘 이해하고 있습니다. 또한 train 데이터와 test 데이터의 유사성이 모델의 성능을 왜 왜곡시킬 수 있는지에 대한 개념을 제대로 이해하고 있습니다.\n\n2. 보완이 필요한 점:\n지원자의 답변은 train 데이터와 test 데이터의 유사성에 대한 설명이 부족합니다. 더 구체적으로 train 데이터가 test 데이터에 누설되면 모델이 실제로 어떻게 오염되는지에 대해 더 깊이 파고들어 설명할 필요가 있습니다.\n\n3. 추가로 언급하면 좋을 내용:\n데이터 누설은 모델의 성능을 과대평가하게 만들 수 있으며, 이는 현실 세계에서 모델을 배포할 때 심각한 문제를 일으킬 수 있습니다. 따라서 데이터 누설을 방지하기 위해 데이터 전처리 및 모델 학습 단계에서 주의 깊게 접근해야 합니다.\n\n4. 개선된 답변 예시:\n\"Test 세트가 오염되었다는 말은, 학습된 모델이 평가를 받을 때 사용되는 test 데이터가 모델 학습에 사용된 train 데이터와 유사하거나 train 데이터에 누설되어 있다는 것을 의미합니다. 이러한 경우, 모델은 실제로는 학습되지 않은 데이터를 예측하는 능력을 정확하게 평가하지 못하게 됩니다. 따라서 모델의 성능을 과대평가하게 되며, 이는 모델의 실제 성능을 왜곡시킬 수 있습니다. 이를 방지하기 위해서는 train 데이터와 test 데이터를 철저히 분리하고, 데이터 누설을 방지하기 위한 전처리 과정을 신중하게 진행해야 합니다.\"\n\n\"핵심 키워드: 데이터 누설, test 데이터, train 데이터, 모델 성능 평가\"",
    "context": "다시  말해 , 누수가  일어나면  모델을  실제로  사용해서  의사  결정을  시작하기  전까지는\n문제점을  찾지  못할  가능성이  높다 . 하지만  그  이후에  모델이  매우  부정확하다는  사실\n을  깨닫게  된다 .\n데이터  누수에는  2 가지  주요  유형이  있다 . 타겟  누수 (target leakage) 와  훈련 - 테스트  오\n염 (train-test contamination) 이  바로  그것이다 .\nTarget leakage\n타겟  누수 (Target leakage) 는  예측  시점에서  사용할  수  없는  데이터가  데이터  셋에  포함\n되어  있을  때  발생한다 . 단순히  어떤  특성이  좋은  예측을  위해  필요한가만  고민하는  것\n뿐만  아니라 , 해당  특성을  사용할  수  있게  되는  타이밍이나  시간  순서의  관점에서  타겟\n누수에  대해  생각해  볼  필요가  있다 .\nTrain-Test Contamination\n또  다른  유형의  누수는  검증  데이터와  훈련  데이터를  제대로  구별하지  않았을  때  발생\n한다 .\n검증  데이터셋  검사는  이전에  고려하지  않았던  데이터들에  대해서  모델의  예측  결과\n를  측정하기  위한  것이다 . 하지만  검증  데이터가  전처리에  영향을  준다면  이  과정이  미\n묘하게  손상될  수  있다 .\n예를  들어  train_test_split 함수를  호출하기  전  전처리를  실행한다고  가정해보자 . 최종\n결과는  어떨까 ? 모델의  검증  점수가  높으므로  신뢰도가  높지만 , 실제로  배포할  때에는\n성능이  저하된다 .\n결국  검증  데이터나  테스트  데이터의  데이터를  예측  방법에  통합했으므로 , 새로운  데\n이터에  일반화할  수  없는  경우에도  특정  데이터에  대해서도  잘  작동할  수도  있다 . 더  복\n잡한  특성  공학을  수행하면  이  문제가  더욱  미묘하고  위험해진다 ."
  },
  {
    "question": "간단한 MNIST 분류기를  TF, PyTorch 등으로  작성하는데  몇시간이  필요한가요 ?",
    "answer": "test\n",
    "feedback": "1. 답변의 좋은 점:\n- 지원자가 TF나 PyTorch를 사용해본 경험이 있다는 점이 좋습니다.\n- 데이터 다운로드부터 모델 설정, 학습, 추론까지의 과정을 언급하여 전체적인 프로세스를 이해하고 있다는 점이 좋습니다.\n\n2. 보완이 필요한 점:\n- 답변이 너무 일반적이고 표면적인 내용에 그치고 있습니다.\n- 구체적인 예시나 경험을 더 추가하여 답변을 더 강화할 필요가 있습니다.\n- 시간적인 측면을 더 구체적으로 언급해야 합니다.\n\n3. 추가로 언급하면 좋을 내용:\n- TF와 PyTorch의 장단점을 비교하거나 어떤 프레임워크를 선택하는 기준에 대해 언급하면 좋을 것입니다.\n- MNIST 분류기를 작성하는 과정에서 어떤 어려움이 있었는지, 어떤 부분을 주의해야 하는지 등 구체적인 경험을 공유하면 좋을 것입니다.\n\n4. 개선된 답변 예시:\nA: TF나 PyTorch를 사용해본 경험이 있습니다. MNIST 분류기를 작성하는데 필요한 시간은 데이터 다운로드, 데이터셋 설정, 모델 구축, 학습 및 추론까지의 과정을 고려하면 대략 2시간 정도 소요될 것으로 생각합니다. 예를 들어, 데이터 전처리 과정에서 이미지 normalization이나 모델 성능 향상을 위한 하이퍼파라미터 튜닝 등에 시간을 소비할 수 있습니다. 또한, PyTorch의 동적 그래프 구조를 활용하면 모델 구현이 더욱 편리해질 수 있습니다.\n\n핵심 키워드: TF, PyTorch, MNIST 분류기, 데이터 전처리, 모델 구축, 하이퍼파라미터, 동적 그래프",
    "context": "Accuracy =============== test acc:0.959 전체로  학습했을  경우  약  98% 까지  가\n능  \"\"\"\n`간단한  MNIST 분류기를  TF, PyTorch 등으로  작성하는데  몇시간이  필요한가요 ?`\n## 답변  -type: answer\nA: TF 나  Pytorch 를  몇  번  사용해본  사람이라면  도큐먼트  참고도  하고  적당히  구글링\n도  하면 , MNIST 분류기의  데이터  다운로드 , 데이터셋 , 데이터로더 , 모델  세팅 , 학습 , 추\n론  를  구현하는데  2 시간이  걸리지  않을  것이라  생각한다 .\n강력한  성능을  내는  모델도  이러한  프레임워크를  사용하면  빠른  시간  내에  구현해낼\n수  있음에  감사하고 , 추상화가  잘  된  함수들일지라도  안에서는  어떤  동작을  하는지  알\n고  사용해야한다 .\n`CNN 이  아닌  MLP 로  해도  잘  될까요 ?`\n## 답변  -type: answer\nA: Convolution 레이어는  receptive field 를  통해  이미지의  위치  정보까지  고려할  수  있\n다는  장점이  있다 .\n반면  MLP 는  모두  Fully connected 구조이므로  이미지의  특징을  이해하는데  픽셀마다\n위치를  고려할  수  없게된다 .\n따라서  MNIST 분류기에서  MLP 를  사용하면  CNN 을  사용했을  때보다  성능이  낮다 .\n24. 11. 26. 오후  1:33 DL 복제\nhttps://www.notion.so/DL-14a92a138a9b80c1a078d4b4545839d7 39/41"
  }
]